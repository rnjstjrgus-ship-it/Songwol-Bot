import streamlit as st
import google.generativeai as genai
from PyPDF2 import PdfReader

# 1. í˜ì´ì§€ ì„¤ì • (ê°€ì¥ ë¨¼ì € í˜¸ì¶œ!)
st.set_page_config(page_title="ì‚¬ë‚´ ê·œì • ì±—ë´‡", icon="ğŸ¢")

# 2. API ì„¤ì •
try:
    api_key = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=api_key)
except Exception as e:
    st.error(f"ğŸš¨ API í‚¤ ì„¤ì • ì—ëŸ¬! Secretsë¥¼ í™•ì¸í•˜ì„¸ìš”. ({e})")
    st.stop()

# 3. PDF ì½ê¸° í•¨ìˆ˜ (ìºì‹± ì ìš©)
@st.cache_resource
def load_data():
    try:
        # íŒŒì¼ëª…ì´ ë°˜ë“œì‹œ rules.pdf ì—¬ì•¼ í•¨!
        reader = PdfReader("rules.pdf")
        full_text = ""
        for page in reader.pages:
            full_text += page.extract_text()
        return full_text
    except Exception as e:
        st.error(f"ğŸš¨ PDF ì½ê¸° ì‹¤íŒ¨! 'rules.pdf' íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ({e})")
        return None

# ë°ì´í„° ë¡œë“œ
data = load_data()

st.title("ğŸ¢ ì‚¬ë‚´ ê·œì • ì±—ë´‡")
st.info("ì‚¬ë‚´ ê·œì • ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ Gemini AIê°€ ë‹µë³€í•©ë‹ˆë‹¤.")

if data:
    # 4. ì±„íŒ… ì„¸ì…˜ ê´€ë¦¬
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ì´ì „ ëŒ€í™” ì¶œë ¥
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # 5. ì‚¬ìš©ì ì…ë ¥ ë° ë‹µë³€ ìƒì„±
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì—°ì°¨ ê·œì • ì•Œë ¤ì¤˜)"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            try:
                # 404 ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ê°€ì¥ ë²”ìš©ì ì¸ ëª¨ë¸ëª… ì‚¬ìš©
                model = genai.GenerativeModel('gemini-1.5-flash')
                
                # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                full_prompt = f"ë„ˆëŠ” íšŒì‚¬ì˜ ì¸ì‚¬íŒ€ ì§ì›ì´ì•¼. ì•„ë˜ì˜ ì‚¬ë‚´ ê·œì • ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê²Œ ë‹µí•´ì¤˜.\n\n[ê·œì • ë‚´ìš©]\n{data}\n\n[ì§ˆë¬¸]\n{prompt}"
                
                response = model.generate_content(full_prompt)
                
                if response.text:
                    st.markdown(response.text)
                    st.session_state.messages.append({"role": "assistant", "content": response.text})
                else:
                    st.warning("AIê°€ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"âŒ AI ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
else:
    st.warning("PDF ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê¹ƒí—ˆë¸Œì— 'rules.pdf'ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
